# Github-Web-Scraper
## A Web Scraper to scrape through the most popular Github Repos in Github

This is an initial try to create a project that shows the utilization of Python Web Scraping libraries, and the integration of some data analysis Libraries such as Pandas, plus some basic knowledge of HTML and CSS(div selecetion, class selection) to create DataFrames that contain the main information of the most popular Repos in Github.

## Stages of the Project
- [x] Importing the Libraries(requests, pandas, numpy)
- [x] Finding the classes (CSS) in the correct DIVS(HTML) to parse through the text.
- [x] Use the right properties and methods to extract the required information.
- [x] Create functions to extract from the page into lists and dictionaries.
- [x] Clean the data put them in functions to simplify and not repeat the code.
- [x] Create csv files containing the entirity of the info about the repos.
- [x] Save the file and can access it anytime.

## Purpose of the Project
This project can be migrated to other sites as well, by using the same thinking pattern, and can highlight how useful it is to know how to parse through information found on the web.Of course Machine Learning frameworks can be applied to this Project such as Natural Language Processing, by parsing through the description text found in the DataFrame that we created.This is an oversimplified approach to webScraping, but I think it can be indicative of how useful WebScraping can be when trying to gather information from the Web, especially for an aspiring Data Scientist such as myself.


## Warnings
 :warning: Always Scrape Websites that allow scraping.
 
 :warning: The file type is .ipynb
